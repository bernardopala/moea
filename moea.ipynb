{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "<h2><b>ALGORYTMY EWOLUCYJNEJ OPTYMALIZACJI WIELOKRYTERIALNEJ</b></h2>\n",
    "\n",
    "<h4><b>Bernard Opala</b></h4>\n",
    "\n",
    "<h4><i>bernard.opala@gmail.com</i></h4>\n",
    "\n",
    "</center>"
   ],
   "id": "e71e88701e0d8a24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Streszczenie\n",
    "Artykuł prezentuje analizę porównawczą wybranych algorytmów ewolucyjnej optymalizacji wielokryterialnej. Do badań wykorzystano algorytmy: NSGA-\n",
    "II, NSGA-III, SPEA2 oraz SPEA3, a skuteczność ich funkcjonowania została zbadana z wykorzystaniem znanych funkcji testowych (tzw. banchmarków): Schaffer,\n",
    "Fonseca, ConstrEx oraz DTLZ2. Eksperymenty numeryczne poprzedzono syntetycznie ujętym wstępem teoretycznym."
   ],
   "id": "badeeacefd66ec6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Słowa kluczowe\n",
    "optymalizacja wielokryterialna, algorytmy ewolucyjne, analiza\n",
    "porównawcza"
   ],
   "id": "619c2401a8f47111"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# WPROWADZENIE\n",
    "Klasyczne (tzw. agregacyjne) metody rozwiązywania problemu optymalizacji wielokryterialnej (np. metoda sumy ważonych celów, czy metoda $\\varepsilon$-ograniczeń [MRW2008}) znajdują tylko jedno rozwiązanie, a uzyskanie kolejnych wymaga zmiany parametrów i ponownego uruchomienia algorytmu. Z tego też powodu, metody te, mają ograniczone zastosowanie. Istnieją alternatywne podejścia, które znajdują wiele rozwiązań. Podejścia te generują zbiór rozwiązań reprezentujących określony poziom kompromisu pomiędzy zadanymi kryteriami (celami) [CCLVV2007, Deb2001, Osyczka2002]. Ważną klasę tego typu metod stanowią algorytmy ewolucyjne (<i> ang. Multi-objective Evolutionary Algorithms - MOEAs</i>) - meta-heurystycznyce, stochastyczne algorytmy rozwiązywania problemów optymalizacyjnych bazujące na mechanizmach doboru naturalnego i dziedziczenia [Goldberg1995, GR2014, GR2016, Michalewicz2003, Rudzinski2016].\n",
    "\n",
    "Praca przedstawia analizę porównawczą wybranych algorytmów MOEA z wykorzystaniem znanych funkcji testowych. Kolejny rozdział w sposób syntetyczny wprowadza do ewolucyjnej optymalizacji wielokryterialnej z uwzględnieniem podstawowych pojęć i definicji. Rozdział trzeci zawiera  przegląd literatury dotyczącej wybranych w pracy algorytmów. W rozdziale czwartym dokonano analizy porównawczej algorytmów ewolucyjnej optymalizacji, na którą składało się wykonanie szeregu eksperymentów numerycznych na wybranych problemach testowych. Ostatni rozdział podsumowuje wyniki przeprowadzonych eksperymentów."
   ],
   "id": "fb3336f9f3e7c867"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PODSTAWOWE POJĘCIA I DEFINICJE\n",
    "Problem optymalizacji wielokryterialnej można zdefiniować następująco:\n",
    "\n",
    "zminimalizuj \n",
    "$$\n",
    "\\begin{equation}\n",
    "f_j (\\boldsymbol{x}), \\quad j=1,2,…,q;\n",
    "\\end{equation}\n",
    "$$\n",
    "przy ograniczeniach\n",
    "$$\n",
    "\\begin{equation}\n",
    "g_k (\\boldsymbol{x}) \\geq 0, \\quad k=1,2,…,r; \\quad\n",
    "h_m (\\boldsymbol{x})=0, \\quad m=1,2,…,s; \n",
    "\\end{equation}\n",
    "$$\n",
    "gdzie $\\boldsymbol{x}=[x_1,x_2,…,x_p ]^T$ jest wektorem $p$ zmiennych decyzyjnych $x_i \\in \\boldsymbol{R} (i=1,2,…,p)$ z uwzględnieniem dopuszczalnych zakresów zmiennych  $x_i^{(min)} \\leq x_i \\leq x_i^{(max)}$, a funkcje $f_j (\\boldsymbol{x})$, $g_k (\\boldsymbol{x})$ i $h_m (\\boldsymbol{x})$ mogą być zarówno ciągłe, jak i dyskretne [Andersson2001, CCLVV2007]. Każde rozwiązanie spełniające powyższe ograniczenia reprezentuje przestrzeń dopuszczalnych (potencjalnych) rozwiązań $\\boldsymbol{\\Omega} \\subset \\boldsymbol{R}^p$. Pozostała przestrzeń nazywa się analogicznie przestrzenią rozwiązań niedopuszczalnych $(\\boldsymbol{R}^p / \\boldsymbol{\\Omega})$. Natomiast, cała przestrzeń $\\boldsymbol{R}^p$ tworzy przestrzeń zmiennych decyzyjnych (parametrów). Z kolei, funkcje celu tworzą wielowymiarową przestrzeń celów $\\boldsymbol{\\Theta} \\subset \\boldsymbol{R}^q$. Zatem dla każdego wektora $\\boldsymbol{x}$ z przestrzeni decyzyjnej $\\boldsymbol{\\Omega}$ istnieje wektor $\\boldsymbol{y} \\in \\boldsymbol{R}^q$ w przestrzeni celów, gdzie $\\boldsymbol{y}=f(\\boldsymbol{x})=[y_1,y_2,…,y_q ]^T$. W rezultacie optymalizacji otrzymuje się zestaw rozwiązań reprezentujących określony poziom kompromisu pomiędzy zadanymi kryteriami.\n",
    "\n",
    "Spośród potencjalnych rozwiązań wybiera się najlepsze, tzw. niezdominowane. Pojęcie dominacji (<i>ang. dominance</i>) należy rozumieć następująco [OJS2003]: rozwiązanie $\\boldsymbol{x}^{(1)}$ dominuje nad innym rozwiązaniem $\\boldsymbol{x}^{(2)}$ $(\\boldsymbol{x}^{(1)} \\succ \\boldsymbol{x}^{(2)})$, jeśli oba poniższe warunki są spełnione jednocześnie:\n",
    "\n",
    "- rozwiązanie $\\boldsymbol{x}^{(1)}$ jest nie gorsze od $\\boldsymbol{x}^{(2)}$ dla wszystkich celów $(\\forall j:f_{j}(\\boldsymbol{x}^{(1)}) \\leq f_{j} (\\boldsymbol{x}^{(2)}))$,\n",
    "- rozwiązanie $\\boldsymbol{x}^{(1)}$ jest lepsze od $\\boldsymbol{x}^{(2)}$ przynajmniej dla jednego z celów $(\\exists j:f_{j}(\\boldsymbol{x}^{(1)}) < f_{j} (\\boldsymbol{x}^{(2)}))$.\n",
    "\n",
    "Przy czym $f_j(\\boldsymbol{x})$ są funkcjami celu $(j=1,2,…,q)$, $\\boldsymbol{x}^{(1)}$ oraz $\\boldsymbol{x}^{(2)}$ są wektorami $p$ zmiennych decyzyjnych, a porównywanie rozwiązań odbywa się w przestrzeni celów. Wszystkie rozwiązania, które są niezdominowane przez żadne inne potencjalne rozwiązanie tworzą zbiór rozwiązań Pareto-optymalnych $\\boldsymbol{F}_{OPT} \\subseteq \\boldsymbol{\\Omega}$, który w przestrzeni celów, z racji przyjmowanego szyku i usytuowania nazwany jest frontem Pareto (<i>ang. Pareto-front</i>). Polepszenie rozwiązań z frontu Pareto pod względem jednego z kryteriów jest niemożliwe bez ich pogorszenia ze względu na inne kryterium. Ogólną koncepcję wyniku procesu optymalizacji wielokryterialnej prezentuje Rys. 1."
   ],
   "id": "6895c62bea62d38d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![title](img/nondominated.jpg)\n",
    "</center>\n",
    "Rys .1. Wizualizacja ogólnej koncepcji procesu optymalizacji wielokryterialnej (liczby przy rozwiązaniach w przestrzeni celów oznaczają liczbę rozwiązań, które nad danym rozwiązaniem dominują (na podstawie \\cite{ZLT2002})}"
   ],
   "id": "cda5061896223263"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "W zdecydowanej większości praktycznych problemów optymalizacji wielokryterialnej zbiór $\\boldsymbol{F}_{OPT}$ jest nieznany lub niemożliwy do ustalenia (np. z powodu nieskończonej liczby rozwiązań Pareto-optymalnych), dlatego zadaniem metod optymalizacji wielokryterialnej jest aproksymacja zbioru Pareto-optymalnego za pomocą zbioru $\\boldsymbol{A}$ zawierającego pewną, zadaną ilość rozwiązań niezdominowanych. Z powodu trudności z uzyskaniem $\\boldsymbol{F}_{OPT}$, wprowadzono dodatkowo pojęcie zbioru odniesienia $\\boldsymbol{F}_{REF}$, który zawiera skończoną liczbę rozwiązań Pareto-optymalnych (bądź rozwiązań znajdujących się tak blisko rozwiązań Pareto-optymalnych, jak to tylko możliwe) uzyskanych w sposób sztuczny, tzn. przy pomocy jakiejś zewnętrznej metody optymalizacji lub analizy matematycznej danego problemu. Zatem, jakość uzyskanego zbioru $\\boldsymbol{A}$ może być określana poprzez porównanie go ze zbiorem $\\boldsymbol{F}_{REF}$ [Rudzinski2015].",
   "id": "a5535a87e67a6331"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PRZEGLĄD ALGORYTMÓW\n",
    "Pierwszym historycznie algorytmem ewolucyjnej optymalizacji wielokryterialnej był zaproponowany w połowie lat 80-tych przez Shaffera algorytm VEGA (<i>ang. Vector Evaluation Genetic Algorithm</i>) [Schaffer1984]. \n",
    "Od tamtej pory powstało wiele podejść wykorzystujących algorytmy ewolucyjne w celu rozwiązania problemów optymalizacji wielokryterialnej, które ze względu na mechanizm wykorzystywany do obliczenia funkcji przystosowania, ogólnie można podzielić na następujące typy [LDZK2015,YXWY2016]:\n",
    "- metody bazujące na relacji dominacji (<i>ang. dominance-based</i>) – wyjaśnione szeroko w dalszej części rozdziału, \n",
    "- metody bazujące na wskaźnikach jakości (<i>ang. indicator-based</i>) wykorzystujące wybrany wskaźnik jakość (np. hiperobjętość) w celu obliczenia funkcji przystosowania rozwiązań oraz \n",
    "- metody bazujące na dekompozycji (<i>ang. decomposition-based</i>) polegające na podziale danego problemu na mniejsze i optymalizowaniu oddzielnie każdego podproblemu w sposób sekwencyjny lub równoległy. \n",
    "\n",
    "Historycznie, wymienia się także metody bazujące na agregacji optymalizowanych funkcji celu (<i>ang. aggregation-based</i>), do których można zaliczyć algorytmy z prac [HL1992, IM1996] oraz metody bazujące na kryteriach (<i>ang. criterion-based</i>), które to w czasie procedury selekcji „przełączają się” pomiędzy zadanymi funkcjami celu, a wybrana funkcja celu decyduje, które osobniki zostaną wybrane do reprodukcji [ZLB2004]. Do ostatniego typu metod można zaliczyć wspomniany algorytm VEGA oraz np. algorytm z pracy [Kursawe1991].\n",
    "\n",
    "Najbardziej popularnymi metodami, stanowiącymi bardzo często punkt odniesienia dla nowych, są metody oparte na relacji dominacji. Do tych metod zalicza się algorytm NSGA-II (<i>ang. Non-dominated Sorting Genetic Algorithm II</i>) [DPAM2002], będący uogólnieniem algorytmu NSGA [SD1995] i algorytm SPEA2 (<i>ang. Strength Pareto Evolutionary Algorithm</i>) [ZLT2002], będący analogicznie uogólnieniem algorytmu SPEA [ZT1999], a także ich kolejne generacje i modyfikacje, m.in. $\\varepsilon$-NSGA-II [DMM2003], NSGA-III [DJ2014] oraz SPEA3 [Rudzinski2015].\n",
    "\n",
    "Podstawowym problemem algorytmu VEGA jest jego zbieżność do rozwiązań, które są najlepsze pod względem jednego z kryteriów, a słabe pod względem pozostałych. Zatem odrzucane są rozwiązania charakteryzujące się dobrym kompromisem ze względu na wszystkie zadane kryteria. Wprowadzenie relacji dominacji do mechanizmu obliczania funkcji przystosowania danego rozwiązania rozwiązuje ten problem, a wsparcie go dodatkowo strategią \"niszowania\" pozwala na zachowanie różnorodności uzyskiwanych rozwiązań. W oparciu o powyższe wskazówki zaproponowane przez Goldberga [Goldberg1995], powstała I generacja algorytmów ewolucyjnej optymalizacji wielokryterialnej. Do tych algorytmów możemy zaliczyć właśnie algorytm NSGA. Wadą  algorytmów I generacji jest brak selekcji elitarnej (zapewniającej najlepszym rozwiązaniom przejście do populacji potomnej podczas kolejnej iteracji algorytmu). Algorytmy II generacji (NSGA-II, SPEA, SPEA2) uwzględniają elitarność w różny sposób. NSGA-II wykorzystuje w tym celu selekcję typu $(\\mu + \\lambda)$, natomiast algorytm SPEA dodatkowy zbiór, tzw. archiwum rozwiązań niezdominowanych, co więcej w SPEA, w celu utrzymania różnorodności populacji wprowadzono technikę klasteryzacji ALM (<i>ang. Average Linkage Method</i>). Poza tym, NSGA-II eliminuje wady poprzednika, do których należą: wysoka złożoność obliczeniowa i wymóg określenia dodatkowego parametru związanego z mechanizmem \"niszowania\" oraz wprowadza tzw. operator stłoczenia (<i>ang. crowded comparison operator</i>) - mechanizm usprawniający zachowanie różnorodności. W SPEA2, także należącym do tej generacji, został poprawiony sposób obliczania funkcji przystosowania, co bezpośrednio przekłada się na poprawę zbieżności algorytmu oraz został zmodyfikowany mechanizm redukcji archiwum, co z kolei pozwala na zagwarantowanie zachowania rozwiązań brzegowych aproksymowanego frontu Pareto.\n",
    "\n",
    "Algorytmy najnowszej generacji można ogólnie podzielić na dwa kierunki rozwoju. Pierwszy, charakteryzuje się udoskonalaniem właściwości algorytmu pod względem następujących kryteriów oceny: dokładność, rozpiętość, zrównoważone rozstawienie oraz złożoność obliczeniowa. Drugi, skupia się na poprawie skuteczności algorytmów w warunkach występowania dużej liczby kryteriów (<i>ang. many-objective optimization</i>) [PF2003]. Do algorytmów reprezentujących pierwszy z kierunków zalicza się np. $\\varepsilon$-NSGA-II oraz algorytm SPEA3. $\\varepsilon$-NSGA-II jest kolejną modyfikacją algorytmu NSGA-II, wprowadzającą dodatkowo archiwum oparte o pojęcie $\\varepsilon$-dominacji, która pozwala użytkownikowi na określenie precyzji z jaką ma być podejmowana decyzja o określeniu danego rozwiązana niezdominowanym, co w efekcie wpływa na zwiększenie szybkości zbieżności algorytmu przy jednoczesnym zachowaniu dobrze zrównoważonego rozstawienia rozwiązań w aproksymowanym froncie Pareto. Z kolei podejście SPEA3 jest uogólnieniem algorytmu SPEA2. Uogólnienie polega na podmianie procedury wymiany środowiskowej z SPEA2 na całkowicie nowa procedurę, która ma za zadanie określić finalne niezdominowane rozwiązania o wysokiej rozpiętości oraz dobrze zrównoważonym rozstawieniu w przestrzeni celów. Podczas procesu optymalizacji ewolucyjnej, rozwiązania niezdominowane są stopniowo wcielane do zbioru wynikowego i rozstawiane tak, że odległości pomiędzy nimi, a ich najbliższymi sąsiadami w przestrzeni celów są najlepsze z możliwych (możliwie jak najbardziej do siebie podobne, aby móc dostarczyć dobrze zrównoważone poziomy kompromisu pomiędzy wartościami zadanych kryteriów). Poza tym, algorytm zachowuje główne zalety SPEA2 - generuje względnie dokładne rozwiązania i pozwala, niezależnie od wielkości populacji na określenie liczby rozwiązań. Drugi kierunek rozwoju prezentuje algorytm NSGA-III. Z racji tego, że wykorzystywany w procedurze selekcji algorytmu NSGA-II mechanizm stłoczenia nie radzi sobie najlepiej przy dużej liczby kryteriów, procedurę zmodyfikowano - wprowadzono bardziej systematyczną analizę generowanych rozwiązań wykorzystując do tego celu punkty referencyjne osadzone na znormalizowanej hiperpłaszczyźnie [DD1998]."
   ],
   "id": "6dfc985ca92a96da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ANALIZA PORÓWNAWCZA\n",
    "W pracy przedstawiono analizę porównawczą wybranych algorytmów MOEA zastosowanych w różnych problemach testowych pod względem dokładności, rozpiętości i rozstawienia zbioru $\\boldsymbol{A}$. Do analizy porównawczej wybrano następujące funkcje testowe: Schaffer, Fonseca, ConstrEx, DTLZ2. Tab. 1. przedstawia szczegóły charakterystyk powyższych funkcji.\n",
    "\n",
    "Jak wspomniano, zadaniem algorytmów optymalizacji wielokryterialnej jest znalezienie zbioru $\\boldsymbol{A}$, który będzie w sposób zadowalający aproksymował front Pareto. Zasadniczo, poszukuje się zbioru $\\boldsymbol{A}$ pod względem jak najlepszego spełnienia następujących kryteriów oceny [OJS2003, Rudzinski2015]:\n",
    "- dokładność (<i>ang. accuracy</i>)  - zbiór $\\boldsymbol{A}$ możliwie jak najlepiej przybliża zbiór $\\boldsymbol{F}_{OPT}$, \n",
    "- rozpiętość (<i>ang. spread</i>) - zbiór $\\boldsymbol{A}$ obejmuje możliwie jak największy zakres rozwiązań niezdominowanych, \n",
    "- zrównoważone rozstawienie (<i>ang. distribution</i>) rozwiązań aproksymowanego frontu Pareto - zbiór $\\boldsymbol{A}$ reprezentuje jak najbardziej równomierne rozłożone poziomy kompromisu ze względu na dane funkcje celu  \n",
    "- złożoność obliczeniowa (<i>ang. computational complexity</i>) - algorytm poszukujący rozwiązań zbioru $\\boldsymbol{A}$ uzyskuje je w możliwie jak najkrótszym czasie, przy wykorzystaniu jak najmniejszej ilości zasobów pamięciowych. \n",
    "\n"
   ],
   "id": "eb5cbef2b1e3ca26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![title](img/test_functions.jpg)\n",
    "\n",
    "Tabela 1. Definicje wykorzystanych funkcji testowych\n",
    "</center>"
   ],
   "id": "aa600243d4dbd5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Powszechnie stosowanymi wskaźnikami jakości w celu uzyskania wspomnianych wyżej własności poszukiwanego zbioru $\\boldsymbol{A}$ są m.in. odległość pokoleniowa $\\mathit{GD}$ (<i>ang. generational distance</i>) [VVL1998] i rozpiętość uogólniona ${\\mathit{\\Delta}}^*$ [ZJZST2006]. Miara $\\mathit{GD}$ – mierzy jak daleko rozwiązania uzyskane podczas danego pokolenia ewolucji są odległe od rozwiązań ze zbioru $\\boldsymbol{F}_{REF}$:\n",
    "$$\n",
    "\\begin{equation}\n",
    "GD\\left(\\boldsymbol{A},\\boldsymbol{F}\\right)=\\frac{1}{\\left|\\boldsymbol{A}\\right|}\\sqrt[q]{\\sum^{\\left|\\boldsymbol{A}\\right|}_{i=1}{d^q_{{\\boldsymbol{AF}}_i}}}\\\n",
    "\\end{equation}\n",
    "$$\n",
    "gdzie $|\\boldsymbol{A}|$ jest liczbą rozwiązań zbioru aproksymującego, $\\boldsymbol{F}$ jest zbiorem odniesienia $\\boldsymbol{F}_{REF}$, a $d_{\\mathbf{A}{\\mathbf{F}}_{i}}$ jest odległością pomiędzy rozwiązaniem $\\boldsymbol{A}_i \\in \\boldsymbol{A}$  a jego najbliższym Pareto-optymalnym sąsiadem ze zbioru $\\boldsymbol{F}$:\n",
    "$$\n",
    "\\begin{equation}\n",
    "d_{{\\boldsymbol{AF}}_{i}}=\n",
    "{\n",
    "\t\\mathop{\\mathrm{min}}_\n",
    "\t{ \n",
    "\t\t\\begin{array}{c} \n",
    "\t\t{F_j \\in \\boldsymbol{F},} \\\\ \n",
    "\t\tj=1,2, \\dots |\\boldsymbol{F}| \n",
    "\t\t\\end{array}\n",
    "\t} \n",
    "\td\\left(A_i,F_j\\right) \n",
    "} \n",
    "\\end{equation}\n",
    "$$\n",
    "W ogólnym przypadku $d\\left(\\mathrm{\\ }{\\boldsymbol{x}}^{\\left(1\\right)}\\mathrm{,\\ }{\\boldsymbol{x}}^{(2)}\\right)$ oznacza odległość pomiędzy rozwiązaniami  ${\\boldsymbol{x}}^{\\left(1\\right)}$ i ${\\boldsymbol{x}}^{(2)}$ w przestrzeni celów. Dla $q=2$, $d_{{\\boldsymbol{AF}}_{i}}$ jest metryką euklidesową:\n",
    "$$\n",
    "\\begin{equation}\n",
    "d\\left(\\mathrm{\\ }{\\boldsymbol{x}}^{\\left(1\\right)}\\mathrm{,\\ }{\\boldsymbol{x}}^{(2)}\\right)\\mathrm{=\\ }\\sqrt{\\sum^n_{j=1}{{\\left(f_j\\left({\\boldsymbol{x}}^{(1)}\\right)-f_j\\left({\\boldsymbol{x}}^{(2)}\\right)\\right)}^2}}. \n",
    "\\end{equation}\n",
    "$$\n",
    "Im wskaźnik $GD\\left(\\boldsymbol{A},\\boldsymbol{F}\\right)$ jest mniejszy, tym rozwiązania ze zbioru aproksymującego $\\boldsymbol{A}$ są bliżej zbioru Pareto-optymalnego $\\boldsymbol{F}$, co oznacza większą dokładność uzyskanych wyników. W celu uzyskania wiarygodnych wyników, wskaźnik wymaga, aby uzyskane rozwiązania ze zbioru $\\boldsymbol{A}$ były znormalizowane.\n",
    "\n",
    "Z kolei, wskaźnikiem mierzącym w przestrzeni celów jednocześnie rozpiętość i rozstawienie rozwiązań ze zbioru aproksymującego $\\boldsymbol{A}$ jest rozpiętość uogólniona ${\\mathit{\\Delta}}^*$ (<i>ang. generalized spread</i>), która jest rozszerzeniem rozpiętości ${\\mathit{\\Delta}}$ (<i>ang. spread</i>) [DPAM2002] zaproponowanej przez Deba dla problemów dwukryterialnych:\n",
    "$$\n",
    "\\begin{equation}\n",
    "{\\mathrm{\\Delta }}^*\\left(\\boldsymbol{A},\\boldsymbol{F}\\right)=\\frac{\\sum^n_{j=1}{d_{{EX}_j}+\\sum^{\\left|\\boldsymbol{A}\\right|-1}_{i=1}{\\left(d_{{NR}_i}-{\\overline{d}}_{NR}\\right)}}}{\\sum^n_{j=1}{d_{{EX}_j}+\\left(\\left|\\boldsymbol{A}\\right|-1\\right){\\overline{d}}_{NR}}},\n",
    "\\end{equation} \n",
    "$$\n",
    "gdzie ${\\overline{d}}_{NR}$ jest średnią ze wszystkich $d_{{NR}_i}$ $\\left(i=1,2,\\dots ,\\left|\\boldsymbol{A}\\right|-1\\right)$, przy czym $d_{{NR}_i}$ jest odległością pomiędzy rozwiązaniem $A_i\\in \\boldsymbol{A}$ a jego najbliższym sąsiadem ze zbioru $\\boldsymbol{A}$:\n",
    "$$\n",
    "\\begin{equation}\n",
    "d_{{NR}_i}={\\mathop{\\mathrm{min}}_{ \\begin{array}{c}\n",
    "A_i\\in \\boldsymbol{A}, \\\\ \n",
    "\\mathrm{j=1,2,\\dots ,}\\left|\\boldsymbol{A}\\right|\\mathrm{;}\\mathrm{i}\\mathrm{\\neq }\\mathrm{j\\ \\ } \\end{array}\n",
    "} d\\left(A_i,A_j\\right)\\ }\n",
    "\\end{equation} \n",
    "$$\n",
    "oraz $d_{{EX}_j}$ jest odległością pomiędzy skrajnymi rozwiązaniami $A_{{EX}_j}\\in \\boldsymbol{A}$ oraz $F_{{EX}_j}\\in \\boldsymbol{F}$:\n",
    "$$\n",
    "\\begin{equation}\n",
    "d_{{EX}_j}=d\\left(A_{{EX}_j},F_{{EX}_j}\\right),\n",
    "\\end{equation}\n",
    "$$ \n",
    "gdzie $A_{{EX}_j}={\\mathop{\\mathrm{argmax}}_{ \\begin{array}{c}\n",
    "A_k\\in \\boldsymbol{A}, \\\\ \n",
    "k=1,\\dots ,\\left|\\boldsymbol{A}\\right| \\end{array}\n",
    "} f_j\\left({\\boldsymbol{x}}_{A_k}\\right)\\ }$ (analogicznie dla $F_{{EX}_j}$). Im wskaźnik ${\\mathrm{\\Delta }}^*\\left(\\boldsymbol{A},\\boldsymbol{F}\\right)$ jest mniejszy, tym rozwiązania ze zbioru aproksymującego mają lepszą rozpiętość (zbiór uwzględnia skrajne rozwiązania) oraz lepsze rozstawienie (odległości pomiędzy sąsiadującymi ze sobą rozwiązaniami są możliwie jak najbardziej do siebie podobne).\n",
    "\n",
    "Przykładowy przebieg procesu ewolucyjnej optymalizacji wielokryterialnej prezentuje Rys. 2. (obliczenia wykonano z wykorzystaniem pakietu jMetal 5.0 [NDV2015])."
   ],
   "id": "2cef3b66e72b5c96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![title](img/generations.jpg)\n",
    "\n",
    "Rys. 2: Prezentacja przebiegu procesu optymalizacji wielokryterialnej z wykorzystaniem algorytmu NSGA-II podczas rozwiązywania problemu testowego Fonseca.\n",
    "</center>"
   ],
   "id": "c199478ab506a380"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "W celu wykonania analizy porównanawczej wybrano następujące algorytmy ewolucyjnej optymalizacji wielokryterialnej: NSGA-II, NSGA-III, SPEA2 oraz SPEA3. Eksperymenty wykonano z wykorzystaniem czterech funkcji testowych: Schaffer, Fonseca, ConstrEx oraz DTLZ2. Funkcje testowe Schaffer, Fonseca, są funkcjami dwukryterialnymi, przy czym nie posiadają ograniczeń, natomiast ConstrEx posiada ograniczenia oraz niezbalansowane zakresy wartości funkcji celu. Z kolei, funkcja DTLZ2 jest funkcją trójkryterialną pochodzącą z pakietu DTLZ. \n",
    "\n",
    "Wszystkie eksperymenty wykonano z wykorzystaniem algorytmów ewolucyjnych o populacji równej 200 osobników, przy czym prawdopodobieństwo krzyżowania oraz prawdopodobieństwo mutacji ustalono na równe odpowiednio 0.7 oraz 0.5. Rozmiar archiwum (w przypadku algorytmów SPEA2 i SPEA3) wynosił 50 osobników, natomiast za liczbę wszystkich generacji przyjęto 10000. Tab. 2. zawiera wyniki uśrednione, uzyskane w wyniku 10-krotnej walidacji krzyżowej. \n",
    "\n",
    "Z wyjątkiem wyników dla algorytmu SPEA3, które pochodzą z pracy [Rudzinski2015], obliczenia wykonano z wykorzystaniem pakietu jMetal 5.0 [NDV2015]. Pakiet jMetal 5.0 jest zorientowaną obiektowo biblioteką języka Java stworzona w celu rozwoju i wykonywania eksperymentów numerycznych z wykorzystaniem zaimplementowanych algorytmów ewolucyjnej (oraz rojowej) optymalizacji wielokryterialnej, zestawów różnorodnych funkcji testowych, problemów i wskaźników jakości. Pakiet jest dostępny w sieci Internet (<i>http://jmetal.github.io/jMetal/</i>), skąd można go pobrać, a co więcej, aktywnie uczestniczyć w jego rozwoju.\n",
    "\n",
    "\n",
    "Uzyskane wyniki prezentuje Tab. 2. Z kolei, Rys. 3-5, przedstawiają w formie wizualnej wybrane aproksymacje frontów Pareto. Jak można zauważyć pod względem rozpiętości i rozstawienia rozwiązań (miara ${\\mathit{\\Delta}}^*$) najlepsze wyniki, dla wszystkich branych pod uwagę funkcji testowych, uzyskuje algorytm SPEA3, czego naoczne potwierdzenie można znaleźć na Rys. 3-5. Z kolei, pod względem dokładności (miara $\\mathit{GD}$), dla problemu Schaffer najlepszy wynik uzyskuje algorytm NSGA-II, dla problemów Fonseca i ConstrEx algorytm SPEA2, natomiast dla problemu DTLZ2 najskuteczniejszy jest algorytm NSGA-III."
   ],
   "id": "e404a8d9e48ec5aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![title](img/results.jpg)\n",
    "\n",
    "Tabela 2. Zbiorcze wyniki analiza porównawczej algorytmów rozwiązujących wybrane funkcje testowe\n",
    "</center>"
   ],
   "id": "27519758d024864"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![title](img/schaffer.jpg)\n",
    "\n",
    "Rys. 3. Finalne aproksymacje zbioru Pareto-optymlanego dla NSGA-II (a), NSGA-III (b), SPEA2 (c) oraz SPEA3 (d) (funkcja testowa Schaffer)\n",
    "</center>"
   ],
   "id": "12cd383c8904a0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![title](img/constrex.jpg)\n",
    "\n",
    "Rys. 4. Finalne aproksymacje zbioru Pareto-optymlanego dla NSGA-II (a), NSGA-III (b), SPEA2 (c) oraz SPEA3 (d) (funkcja testowa ConstrEx)\n",
    "</center>"
   ],
   "id": "bf6be6d4fe0fe58b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![title](img/dtlz2.jpg)\n",
    "\n",
    "Rys. 5. Finalne aproksymacje zbioru Pareto-optymlanego dla NSGA-II (a), NSGA-III (b), SPEA2 (c) oraz SPEA3 (d) (funkcja testowa DTLZ2)\n",
    "</center>"
   ],
   "id": "63be01b7a269db97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# WNIOSKI\n",
    "W pracy przedstawiono analizę porównawczą wybranych algorytmów ewolucyjnej optymalizacji wielokryterialnej (NSGA-II, NSGA-III, SPEA2 oraz SPEA3) zastosowanych w różnorodnych problemach testowych (Schaffer, Fonseca, ConstrEx oraz DTLZ2). Spośród rozważanych podejść, algorytm SPEA3 generuje rozwiązania o najbardziej zrównoważonym kompromisie pomiędzy zadanymi kryteriami dla wszystkich rozważanych funkcji testowych. Na uwagę zasługuje także algorytm NSGA-III. Algorytm ten, daje najgorsze wyniki w przypadku optymalizacji funkcji testowych o dwóch kryteriach, co można zobaczyć na Rys. 3. i na Rys. 4. Rozwiązań jest zdecydowanie mniej, a ich rozstawienie jest nierównomierne - rozłożone są rzadziej na końcach zakresów funkcji, a gęściej w pobliżu środka. Z kolei, dla problemu trójkryterialnego DTLZ2, algorytm NSGA-III uzyskuje najlepszą dokładność. Poza tym, pod względem dokładności, najlepsze wyniki dla problemów Fonseca i ConstrEx uzyskuje algorytm SPEA2, a dla problemu Schaffer, algorytm NSGA-II."
   ],
   "id": "6c86f90b0714b0e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bibliografia\n",
    "\n",
    "<b>[Andersson2001]</b> Andersson J. (2001) <i>A Survey of Multiobjective Optimization in Engineering Design</i>, Technical Report LiTH-IKP-R-1097, Department of Mechanical Engineering, Link{\\\"o}ping University, Link{\\\"o}ping, Sweden.\n",
    "\n",
    "<b>[CCLVV2007]</b> Coello Coello C., Lamont G.B., Van Veldhuizen D.A. (2007) <i>Evolutionary algorithms for solving multi-objective problems</i>, Springer.\n",
    "\n",
    "<b>[DD1998]</b> Das I., Dennis J. (1998), <i>Normal-boundary intersection: A new method for generating the Pareto surface in nonlinear multicriteria optimization problems</i>, SIAM Journal of Optimization, \\textbf{8}, 3, 631–657.\n",
    "\n",
    "<b>[Deb2001]</b> Deb K. (2001) <i>Mulit-Objective Optimization using Evolutionary Algorithms</i>, John Wiley \\& Sons.\n",
    "\n",
    "<b>[DPAM2002]</b> Deb K., Pratap A., Agarwal S., Meyarivan T. (2002) <i>A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation</i>, \\textbf{6}, no. 2, pp. 182-197.\n",
    "\n",
    "<b>[DMM2003]</b> Deb K., Mohan M., Mishra S. (2003), <i>A fast multi-objective evolutionary algorithm for finding well-spread Pareto-optimal solutions</i>, Tech. Rep. KanGAL 2003002, Indian Institute of Technology, Kanpur.\n",
    "\n",
    "<b>[DJ2014]</b> Deb K., Jain H. (2014), <i>An Evolutionary Many-Objective Optimization Algorithm Using Reference-point Based Non-dominated Sorting Approach, Part I: Solving Problems with Box Constraints</i>, IEEE Transactions on Evolutionary Computation, \\textbf{18}, Issue: 4, 577-601.\n",
    "\n",
    "<b>[Goldberg1995]</b> Goldberg D.E. (1995) <i>Algorytmy genetyczne i ich zastosowania</i>, WNT, Warszawa.\n",
    "\n",
    "<b>[GR2014]</b> Gorzałczany M.B., Rudziński F. (2014), <i>Fuzzy modelling of road traffic collision patterns using multi-objective genetic optimization method</i>, Logistyka, \\textbf{6}, 4102-4111.\n",
    "\n",
    "<b>[GR2016]</b> Gorzałczany M.B., Rudziński F. (2016), <i>A multi-objective genetic optimization for fast, fuzzy rule-based credit classification with balanced accuracy and interpretability</i>,  Applied Soft Computing, \\textbf{40}, 206-220.\n",
    "\n",
    "<b>[KR2006]</b> Kollat J.B., Reed P.M. (2006), <i>Comparing state-of-the-art evolutionary multi-objective algorithms for long-term groundwater monitoring design</i>, Advances in Water Resources, \\textbf{29}, 6, 792-807.\n",
    "\n",
    "<b>[HL1992]</b> Hajela P., Lin C.-Y. (1992), <i>Genetic search strategies in multicriterion optimal design</i>, Structural Optimization, \\textbf{4}, 99–107.\n",
    "\n",
    "<b>[IKK2001]</b> Ikeda K., Kita H., Kobayashi S. (2001), <i>Failure of Pareto-based MOEAs: Does non-dominated really mean near to optimal?</i>, Proc. IEEE Congr. Evol. Comput., \\textbf{2}, 957–962, Seul, Korea.\n",
    "\n",
    "<b>[IM1996]</b> Ishibuchi H., Murata T. (1996), <i>Multi-objective genetic local search algorithm</i>, Proceedings of IEEE International Conference on Evolutionary Computation (ICEC’96), 119–124, Piscataway, NJ, IEEE Press.\n",
    "\n",
    "<b>[KYD2003]</b> Khare V., Yao X., Deb K. (2003), <i>Performance scaling of multi-objective evolutionary algorithms</i>, Proc. Evol. Multi-Criter. Optim., 376–390, Faro, Portugalia.\n",
    "\n",
    "<b>[Kursawe1991]</b> Kursawe F. (1991), <i>A variant of evolution strategies for vector optimization</i>, Parallel Problem Solving from Nature, 193–197, Springer, Berlin.\n",
    "\n",
    "<b>[LDZK2015]</b> Li K., Deb K., Zhang Q., Kwong S. (2015), <i>An Evolutionary Many-Objective Optimization Algorithm Based on Dominance and Decomposition</i>, \\textbf{19}, Issue: 5, 694-716.\n",
    "\n",
    "<b>[Michalewicz2003]</b> Michalewicz Z. (2003), <i>Algorytmy genetyczne + struktury danych = program ewolucyjne</i>, WNT, Warszawa.\n",
    "\n",
    "<b>[MF2006]</b> Michalewicz Z., Fogel D.B. (2006), <i>Jak to rozwiązać, czyli nowoczesna heurystyka</i>, WNT, Warszawa.\n",
    "\n",
    "<b>[MRW2008]</b> Miettinen K., Ruiz F., Wierzbicki A.P. (2008), <i>Introduction to Multiobjective Optimization: Interactive Approaches</i>, Lecture Notes in Computer Science, \\textbf{5252}, 27-57, Springer-Verlag, Berlin Heidelberg.\n",
    "\n",
    "<b>[NDV2015]</b> Nebro A.J., Durillo J.J., Vergne M. (2015), <i>Redesigning the jMetal Multi-Objective Optimization Framework</i>, GECCO (Companion) 2015, pp. 1093-1100.\n",
    "\n",
    "<b>[OJS2003]</b> Okabe T., Jin Y., Sendhoff B. (2003), <i>A critical survey of performance indices for multiobjective optimization</i>, In Proceeding of the IEEE Congress on Evolutionary Computation, 979-885, IEEE Press.\n",
    "\n",
    "<b>[Osowski2013]</b> Osowski S. (2013), <i>Metody i narzędzia eksploracji danych</i>, BTC, Warszawa\n",
    "\n",
    "<b>[Osyczka2002]</b> Osyczka A. (2002), <i>Evolutionary Algorithms for Single and Multicriteria Design Optimization</i>, Physica-Verlag.\n",
    "\n",
    "<b>[PF2003]</b> Purshouse R. C., Fleming P. J. (2003), <i>Evolutionary many-objective optimisation: An exploratory analysis</i>, Proc. IEEE Congr. Evol. Comput., \\textbf{3}, 2066–2073, Canberra, Australia.\n",
    "\n",
    "<b>[Rudzinski2015]</b> Rudziński F. (2015), <i>Finding Sets of Non-Dominated Solutions with High Spread and Well-Balanced Distribution using Generalized Strength Pareto Evolutionary Algorithm</i>, Advances in Intelligent Systems Research, \\textbf{89}, 178-185.\n",
    "\n",
    "<b>[Rudzinski2016]</b> Rudziński F. (2016), <i>A multi-objective genetic optimization of interpretability-oriented fuzzy rule-based</i>, Applied Soft Computing, \\textbf{38}, 118-133, Elsevier.\n",
    "\n",
    "<b>[Rutkowski2011]</b> Rutkowski L. (2011), <i>Metody i techniki sztucznej inteligencji</i>, PWN, Warszawa.\n",
    "\n",
    "<b>[Schaffer1984]</b> Schaffer D. J. (1984), <i>Multiple Objective Optimization with Vector Evaluated Genetic Algorithms</i>, Ph.D. thesis, Vanderbilt University\n",
    "\n",
    "<b>[SD1995]</b> Srinivas N., Deb K. (1995), <i>Multiobjective function optimization using nondominated sorting genetic algorithms</i>, Evol. Comput., textbf{2}, no. 3, 221–248.\n",
    "\n",
    "<b>[VVL1998]</b> Van Veldhuizen D.A., Lamont G.B. (1998), <i>Multiobjective evolutionary algorithm research: A history and analysis</i>, Tech. Rep TR-98-03, Dept. Elec. Comput. Eng., Graduate School of Eng., Air Force Inst. Technol., Wright-Patterson, AFB, OH.\n",
    "\n",
    "<b>[YXWY2016]</b> Yuan Y., Xu H., Wang B., Yao X. (2016), <i> A New Dominance Relation-Based Evolutionary Algorithm for Many-Objective Optimization</i>, IEEE Transactions on Evolutionary Computation, \\textbf{20}, 1, 16-37. \n",
    "\n",
    "<b>[ZJZST2006]</b>\tZhou A., Jin Y., Zhang Q., Sendhoff B., Tsang E. (2006), <i>Combining Model-based and Genetics-based Offspring Generation for Multi-objective Optimization Using a Convergence Criterion</i>, Proceeding of the IEEE Congress on Evolutionary Computation, 892-899. IEEE Press.\n",
    "\n",
    "<b>[ZT1999]</b> Zitzler E., Thiele L. (1999), <i>Multiobjective evolutionary algorithms: A comparative case study and the strength pareto approach</i>, IEEE Transactions on Evolutionary Computation, texetbf{3},4, 257-271.\n",
    "\n",
    "<b>[ZLT2002]</b> Ziztler E., Laumanns M., Thiele L. (2002), <i>SPEA2: Improving the strength pareto evolutionary algorithm for multiobjective optimization</i>, Proceeding of the Evolutionary Methods for Design, Optimisation and Control, 95-100. CIMNE, Barcelona, Hiszpania.\n",
    "\n",
    "<b>[ZLB2004]</b> Zitzler E., Laumanns M., Bleuler S. (2004) <i>A Tutorial on Evolutionary Multiobjective Optimization</i>, Lecture Notes in Economics and Mathematical Systems, \\textbf{535}, Part I, 3-37, Springer-Verlag, Berlin-Heidelberg.\n"
   ],
   "id": "20caf5486115786c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center><h2><b>MULTI-OBJECTIVE EVOLUTIONARY ALGORITHMS</b></h2></center>\n",
    "\n",
    "<h3>Abstract</h3>\n",
    "\n",
    "The paper presents a comparative analysis of the selected evolutionary multiobjective algorithms, i.e., NSGA-II, NSGA-III, SPEA2 and SPEA3. The performance of considered approaches has been tested with the use of 4 well-known two- and three-objective optimization benchmark problems (i.e., Schaffer, Fonseca, ConstrEx and DTLZ2). Experimental studies have been preceded by brief theoretical study."
   ],
   "id": "b6cfb1f4576661ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "80f3bd42b0f2520a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312_moea",
   "language": "python",
   "name": "p312_moea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
